{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Server-inout online GColab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLRMDIJkUkvM/D4dnSXwyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olgasc/Colab-SPKPrime/blob/main/Server_inout_online_GColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSOJrx1WAOnQ"
      },
      "source": [
        "#**Colab - Spike Prime**\n",
        "\n",
        "Using *Colab's Virtual Machine* to save data from Spike Prime and send python files to run on the Spike Prime brick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N9tMS0_24i"
      },
      "source": [
        "**1.- Installing flask, pyngrok and flask-ngrok packages**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Installing flask, pyngrok and flask-ngrok packages to create a server accessible from internet in https://XXXX.ngrok.io\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba1fVSwHC6HT"
      },
      "source": [
        "!pip install flask\n",
        "!pip install pyngrok\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4_zwCKOn0QB"
      },
      "source": [
        "***`Why have we installed flask-ngrok?`***\n",
        "\n",
        "The reason is that the flask server creates a server that runs locally on the allocated runtime on google colab as localhost. In order to expose the server to the outside traffic or to make the server accessible outside the runtime globally on HTTP, we use ngrok here and since we are working with flask it is good to use flask-ngrok module of python.(https://github.com/SAH-UJA/Flask_on_colab/blob/main/Flask_and_FastAPI_on_colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGPAzJpQ5Eqf"
      },
      "source": [
        "## Install package \"***flask-jsonpify***\"\n",
        "\n",
        "To send data between Flask and Javascript using AJAX, we need to use \"**JsonP**\" data format to avoid CORS issues due security policy about cross-origins executions.\n",
        "\n",
        "In this case, when we send a file or any data from Flask to Javascript we need to convert it to **JsonP** format.\n",
        "\n",
        "\"flask-jsonpify\" allows to convert a python file to jsonp. Inside flask application code we will call \"*from flask_jsonpify import jsonify*\", and in the \"return\" we will convert the output (python file) to jsonp type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOgqq4GZst_-"
      },
      "source": [
        "!pip install flask-jsonpify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bxmCMFc4Jjz"
      },
      "source": [
        "## Upload python files to execute on Spike Prime\n",
        "\n",
        "For calling a python file to be executed on the Spike Prime, we have to upload the files on the path \"*content/files/*\":\n",
        "\n",
        "1. Create under \"*content*\" the folder \"*files*\"\n",
        "2. Upload the python files\n",
        "\n",
        "**The path \"content/files/\" can be modified. You have to be sure to change the path from retrieving the python file to return on the flask route (@app.route('/file/'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fxcsO4nAnfq"
      },
      "source": [
        "**2.-  Create Flask server** with a public IP address on ngrok.io\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This means ngrok is exposing our web app onto the temporary URL http://XXXXXXX.ngrok.io (it is different every time it is run). If we go to this URL we get our home page: \"*Connected*\".\n",
        "\n",
        "In \"/data\" the server save the data from Spike Prime in a .csv file in Colab Virtual Machine (*\"/content/test.csv\"*) temporaly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n392Gp_qDotw"
      },
      "source": [
        "from flask import Flask, request, send_file, json\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import csv\n",
        "from flask_jsonpify import jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "run_with_ngrok(app)   \n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h1>Connected</h1>\"\n",
        "\n",
        "@app.route(\"/data\", methods=['GET', 'POST'])\n",
        "def data():\n",
        "    data = request.args.get(\"Sensor_data\")\n",
        "    time = request.args.get(\"Timestamp\")\n",
        "    if (time=='0'):\n",
        "      print(\"***Starting receiving data****\")\n",
        "      with open('/content/test.csv', mode='w') as csvfile:\n",
        "        fieldnames= ['Timestamp', 'sensor_data']\n",
        "        writer=csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer1 = csv.writer(csvfile)\n",
        "        writer1.writerow([time, data])\n",
        "\n",
        "        print({'timestamp':time, 'Sensor_data':data})\n",
        "    elif (time == '-1'):\n",
        "        print(\"End receving data\")\n",
        "    else:\n",
        "      with open('/content/test.csv', mode='a') as csvfile:\n",
        "        writer = csv.writer(csvfile, delimiter=',')\n",
        "        writer.writerow([time, data])\n",
        "        print({'timestamp':time, 'Sensor_data':data})\n",
        "    return (data)\n",
        "\n",
        "@app.route(\"/file/<namefile>\", methods=['GET'])\n",
        "def return_file(namefile):\n",
        "  print(namefile)\n",
        "  file=namefile+'.py'\n",
        "  with open('/content/files/'+file, mode='r') as f:\n",
        "    content=f.read()\n",
        "  return jsonify(content)\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziaaOe9s21q_"
      },
      "source": [
        " **3.- Read data sensor from file**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vquPCqq-20y8"
      },
      "source": [
        "import pandas\n",
        "df = pandas.read_csv('/content/test.csv')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yIQRchKVhTc"
      },
      "source": [
        " **4.- Plot Data Sensor**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyKHQUVot4oo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "  \n",
        "x = []\n",
        "y = []\n",
        "  \n",
        "with open('/content/test.csv', 'r') as csvfile:\n",
        "    reader=csv.reader(csvfile,delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "    \n",
        "      x.append(row[0])\n",
        "      y.append(int(row[1]))\n",
        "  \n",
        "plt.plot(x, y, color = 'g', linestyle = 'dashed',\n",
        "         marker = 'o',label = \"Data Sensor\")\n",
        "  \n",
        "plt.xticks(rotation = 25)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Data_Sensor')\n",
        "plt.title('Sensor Report', fontsize = 20)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnjD4Kyrde5v"
      },
      "source": [
        "## Save Sensor data file .csv as a Google Sheet into our Google account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n7m5Lex6QEL"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "# Create our spreadsheet\n",
        "sh = gc.create('Data Sensor')\n",
        "\n",
        "# Read CSV file contents\n",
        "content = open('/content/test.csv', 'r').read()\n",
        "\n",
        "#Imports data into the first page of the spreadsheet.\n",
        "#This method removes all other worksheets and then entirely replaces the contents of the first worksheet.\n",
        "gc.import_csv(sh.id, content)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YHQq7gE4e5c"
      },
      "source": [
        "## Downloading data from a sheet into Python as a Pandas DataFrame\n",
        "\n",
        "Read back the random data that we inserted above and convert the result into a Pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPiH5ifn4foa"
      },
      "source": [
        "worksheet = gc.open('Data Sensor').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "print(rows)\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}